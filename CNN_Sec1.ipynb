{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import keras as keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Activation, add, Add, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson2 畳み込みニューラルネットワーク(CNN)\n",
    "\n",
    "## Section1 解説\n",
    "\n",
    "### 1.1 CNN基礎\n",
    "**ConvolutioalNeuralNetwork**(**CNN**)は、画像認識、音声認識,自然言語処理などにおいて幅広く使用されている。\n",
    "\n",
    "Lesson1のMLPは全結合(Dense)層のみで構成されていたが、CNNは**Convolution(畳み込み)層**と**Pooling(プーリング)層**を組み合わせて構築していく。(出力に近い層は全結合層を組み合わせることも多く、全結合層も使用する)\n",
    "\n",
    "CNNにおいて重要なのは、\n",
    "- 局所結合・重み共有による**パラメータ削減**\n",
    "- **不変性**\n",
    "\n",
    "であり、それぞれ畳み込み層・プーリング層に対応する。\n",
    "\n",
    "#### 1.1.1 局所結合によるパラメータ削減\n",
    "\n",
    "2次元の画像では、近いところにある画素同士の関係性が強いのに対して、離れた場所にある画素同士の関係性は薄いと考えられる。\n",
    "\n",
    "CNNの畳み込み層では、近い画素同士の結合のみを考えることでパラメータを削減している。\n",
    "\n",
    "下図に全結合層のイメージを示す。入力のすべてのユニットは出力のすべてのユニットと結合を持っていることが分かる。(下図のパラメータ数は5×5=25)\n",
    "\n",
    "![全結合層image](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/sparse_1.png)\n",
    "\n",
    "これに対し、CNNの畳み込み層では出力のユニットは**入力のある一定範囲に対してのみ結合**を持つ。下図にCNNの畳み込み層のイメージを示す。パラメータ数が13となっていて、この例では約半分にできていることが分かる。\n",
    "\n",
    "![CNNの畳み込み層image](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/sparse_2.png)\n",
    "\n",
    "全結合層では画素同士の位置関係の情報を排除(ベクトルに落とし込んでいた)していたのに対し、畳み込み層では画素同士の情報を保持したまま扱うことで、結合を疎にすることを可能にしている。\n",
    "\n",
    "#### 1.1.2 重み共有によるパラメータ削減\n",
    "\n",
    "ある画像がネコであるかそうでないかを判別するときに、画像内のどこにネコがいるかはどうでもよい。\n",
    "\n",
    "全結合層では層間で1つのパラメータは1度だけ使われるが、畳み込み層では入力のすべての位置で同じパラメータを使用する。(重み共有)\n",
    "\n",
    "下図に全結合層でのパラメータ使用のイメージを示す。1つの重み(黒い矢印)は特定のユニット間でのみ使用される。\n",
    "\n",
    "![全結合層パラメータimage](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/sharing_2.png)\n",
    "\n",
    "下図に畳み込み層でのパラメータ使用のイメージを示す。畳み込み層では1つの重み(黒い矢印)はすべての場所で使用される。\n",
    "\n",
    "![畳み込み層パラメータimage](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/sharing_1.png)\n",
    "\n",
    "畳み込み層ではどこにあるかという情報を捨象し、なにがあるかのみを残すことでパラメータを大幅に削減している。入力画像が大きくなってもパラメータ数は増えない。\n",
    "\n",
    "使用するパラメータ数を抑えることで、学習を効率的に進めることができる。\n",
    "\n",
    "ただし、どこにあるのかという位置情報が重要な場合は、画像内の位置によって異なるパラメータを使用する場合がある。\n",
    "\n",
    "#### 1.1.3 不変性\n",
    "\n",
    "プーリング層では、獲得した特徴のゆがみやズレに対しての頑強性をあげるため、小さな領域での統計量(Max, Mean)などを取る。また、画像サイズを小さくする役割もある。\n",
    "\n",
    "![プーリング層](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "\n",
    "**ネットワークの構成**\n",
    "\n",
    "基本的には、\n",
    "\n",
    "畳み込み層→プーリング層→畳み込み層→プーリング層→・・・\n",
    "\n",
    "というように畳み込みとプーリングを繰り返してく。全結合層は位置情報を失うため、ネットワークの最後でのみ使用する。\n",
    "\n",
    "最初の方の層で局所的な特徴(エッジ等)を抽出し、層が進むにつれ大局的な特徴(タイヤ等)を抽出することができる。\n",
    "\n",
    "![階層的な概念の抽出](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/cnn_feature_extraction.png)\n",
    "\n",
    "このような**階層的な概念の抽出**が深層学習の大きな特徴である。\n",
    "\n",
    "以下でそれぞれの層を具体的に説明していく。\n",
    "\n",
    "### 1.2 Convolution(畳み込み)層\n",
    "#### 1.2.1 畳み込み層の考え方\n",
    "畳み込み層における畳み込みとは、入力に対してフィルターをかけた(畳みこんだ)ときに得られる値のこと。\n",
    "\n",
    "#### 1.2.2 2次元入力に対する畳み込み\n",
    "畳み込み計算は下図のように行う。\n",
    "![畳み込み計算](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/conv.png)\n",
    "\n",
    "畳み込み層ではある領域においてのフィルターに対する類似度のようなものを計算している。\n",
    "フィルターは１つの特徴に対応するので、複数のフィルターを設定することでより複数の特徴を獲得していると考えられる。\n",
    "フィルターのサイズを大きくすると広い範囲の特徴を、小さくすると小さな範囲の特徴を獲得することが出来る。\n",
    "\n",
    "#### 1.2.3 3次元入力に対する畳み込み\n",
    "CNNでの各層の入力は実際には(縦のピクセル数)×(横のピクセル数)×(フィルター数)の3階テンソルとなっている。それに合わせて、フィルターも3階テンソルとなっているが、畳み込みの考え方自体は2次元と同様。\n",
    "\n",
    "#### 1.2.4 パラメータ削減の例\n",
    "全結合層を畳み込み層で置き換えることで実際にどれくらいのパラメータを削減できるかを見てみる。\n",
    "\n",
    "入力画像が10×10×3(合計300ピクセル)の場合\n",
    "\n",
    "全結合層でユニット数300の隠れ層につなぐ場合、パラメータ数は300×300×300=90300となる。\n",
    "\n",
    "畳み込み層で考えると、5×5×3のフィルターを100枚用いた場合は、5×5×3×100=7600となり、全結合層のパラメータ数の約1/12。\n",
    "\n",
    "また、全結合層では入力画像のサイズに比例してパラメータ数が増えるが、畳み込み層では増えないのでパラメータ削減の効果は入力画像が大きくなるにつれ大きくなる。\n",
    "\n",
    "#### 1.2.5 出力のサイズ\n",
    "入力の縦or横の次元数を$N$、フィルタの縦or横の次元数を$F$、フィルタを動かす幅を$S$とすると、出力のサイズは以下の様に計算できる。\n",
    "\n",
    "$$\n",
    "(N-F)/S+1\n",
    "$$\n",
    "\n",
    "#### 1.2.6 パディング\n",
    "1.2.2の畳み込み計算の図を見ると、出力のサイズ(2, 3)は入力のサイズ(3, 4)よりも少し小さくなっている。このように、入力に対してそのまま畳み込みを行うと特徴マップのサイズは縮小する。\n",
    "\n",
    "下図では、16次元の入力に対してサイズ6のフィルタ－で畳み込みを行っている。畳み込みのたびに特徴マップのサイズが縮小しているので、3層までしか進むことが出来ない。\n",
    "\n",
    "![16次元の入力に対するサイズ6の畳み込み](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/pool_1.png)\n",
    "\n",
    "特徴マップが縮小してしまうのを防ぐために入力の両端に対して0などの値をくっつける。これを**パディング**という。下図では左端に3つ、右端に3つずつユニットを追加している。\n",
    "\n",
    "![パディング](https://github.com/matsuolab-edu/dl4us/raw/b34f8964fe3cdbbf0dd527dc381926721538ac8c/lesson2/figures/pool_2.png)\n",
    "\n",
    "パディングをしないと、特徴マップの端の方のユニットは中央よりも畳み込みされる回数が少ないので、情報として過少に評価されていると考えられる。パディングにより、端の方のユニットに対する畳み込みの回数が増えるので、端の方に重要な情報がある場合には有効だと考えることが出来る。\n",
    "\n",
    "何もくっつけないパディング(パディングしない、出力のサイズが小さくなる)\n",
    "を**Valid**、入力と出力のサイズが変わらないようにするパディングを**Same**という。\n",
    "\n",
    "#### 1.2.7 Kerasによる実装\n",
    "Kerasで畳み込み層を設定するには、keras.layers.Conv2Dを使用する。\n",
    "\n",
    "主な引数\n",
    "- filters : フィルター(カーネル)の数\n",
    "- kernel_size : フィルターの大きさ\n",
    "- strides : フィルターを動かす幅\n",
    "- padding : パディング\n",
    "- activation : 活性化関数\n",
    "- use_bias : バイアス項の有無"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; justify-content: row;\">\n",
       "    <img src=\"https://i.giphy.com/media/6EjTPebp1oWxG/giphy.gif\">\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "HTML('''<div style=\"display: flex; justify-content: row;\">\n",
    "    <img src=\"https://i.giphy.com/media/6EjTPebp1oWxG/giphy.gif\">\n",
    "</div>''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上のgifと同じ操作を行うコードをサンプルとしていかに示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 3., 4.],\n",
       "       [2., 4., 3.],\n",
       "       [2., 3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプル画像 (5x5)\n",
    "sample_image = np.array([[1, 1, 1, 0, 0],\n",
    "                         [0, 1, 1, 1, 0],\n",
    "                         [0, 0, 1, 1, 1],\n",
    "                         [0, 0, 1, 1, 0],\n",
    "                         [0, 1, 1, 0, 0]]\n",
    "                        ).astype('float32').reshape(1, 5, 5, 1)\n",
    "\n",
    "# フィルタ\n",
    "W = np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]]).astype('float32').reshape(3, 3, 1, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                 padding='valid', input_shape=(5, 5, 1), use_bias=False))\n",
    "model.layers[0].set_weights([W])\n",
    "\n",
    "model.predict(sample_image).reshape(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Pooling(プーリング)層\n",
    "#### 1.3.1 プーリングの考え方\n",
    "小さな領域に対して統計量(Max, Mean)を取ることで、一のズレなどに対して頑強な特徴抽出を行う。\n",
    "\n",
    "#### 1.3.2 Kerasによる実装\n",
    "Kerasで畳み込み層を設定するにはMaxPooling2D、AveragePooling2D、GlobalMaxPooling2D、GlobalAveragePooling2Dを使用する。\n",
    "\n",
    "主な引数\n",
    "- pool_size : プーリングする領域のサイズ\n",
    "- strides : ウィンドウを動かすサイズ\n",
    "- padding : パディング\n",
    "\n",
    "![pooling_keras](http://cs231n.github.io/assets/cnn/maxpool.jpeg)\n",
    "\n",
    "上図と同じ操作を行うコードを以下にサンプルとして示す。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 8.],\n",
       "       [3., 4.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプル画像\n",
    "sample_image = np.array([[1, 1, 2, 4],\n",
    "                         [5, 6, 7, 8],\n",
    "                         [3, 2, 1, 0],\n",
    "                         [1, 2, 3, 4]]\n",
    "                        ).astype(\"float32\").reshape(1, 4, 4, 1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None,\n",
    "                       padding='valid', input_shape=(4, 4, 1)))\n",
    "\n",
    "model.predict(sample_image).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
