{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 実装①\n",
    "\n",
    "LSTMを使ったSeq2Seqモデルで英日機械翻訳を行ってみる。\n",
    "\n",
    "使用するデータセット、train.enとtrain.jaの中身は以下のようになっている。\n",
    "\n",
    "train.enの中身 (英語の文)\n",
    "\n",
    "i can 't tell who will arrive first .\n",
    "many animals have been destroyed by men .\n",
    "i 'm in the tennis club .\n",
    "︙\n",
    "\n",
    "train.jaの中身(日本語の文, 対訳)\n",
    "\n",
    "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
    "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
    "私 は テニス 部員 で す 。\n",
    "︙\n",
    "\n",
    "### 2.0 データの用意\n",
    "\n",
    "まず、データを読み込む。\n",
    "\n",
    "読み込む際に、文頭を表す仮想単語(**BOS**, Beggining Of Sentence)として＜s＞、文末を表す仮想単語(**EOS**, End Of Sentence)として＜¥s＞を付加する。\n",
    "\n",
    "また、BOS・EOSをつけた文章について、Tokenizerによって数値化を行う。\n",
    "\n",
    "最後に、バッチ処理のため、各系列の長さをそろえておく。keras.preprocessing.sequence.pad_sequenceを用いる。\n",
    "\n",
    "<img src=figures/preprocess.png>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanor\\Anaconda3\\envs\\matsuo\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(file_path):\n",
    "    tokenizer = Tokenizer(filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
    "\n",
    "# 読み込み＆Tokenizerによる数値化\n",
    "x_train, tokenizer_en = load_data('data/train.en')\n",
    "y_train, tokenizer_ja = load_data('data/train.ja')\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.02, random_state=42)\n",
    "\n",
    "# パディング\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "\n",
    "seqX_len = len(x_train[0])\n",
    "seqY_len = len(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 モデル構築\n",
    "ここではLSTMを使用してSeq2Seqモデルを構築してみる。\n",
    "\n",
    "Embeddingレイヤーでは、mask_zero=Trueを指定することで、計算時に前述したパディング部分を無視するようにしている。\n",
    "\n",
    "また、Reccurentレイヤーに対するreturn_state=Trueやreturn_sequence=Trueの指定をLSTMレイヤーの生成時に行っている。\n",
    "\n",
    "※Functional APIによるモデル構築であることに注意\n",
    "\n",
    "<img src=figures/model.png>\n",
    "\n",
    "上図での各レイヤーの対応\n",
    "- 符号化器Embeddingレイヤー : EncoderのEmbedding\n",
    "- 符号化器再帰レイヤー : Encoder(LSTM)\n",
    "- 復号化器Embeddingレイヤー : DecorderのEmbedding\n",
    "- 復号化器再帰レイヤー : Decorder(LSTM)\n",
    "- 復号化器出力レイヤー : Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, LSTM\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "\n",
    "## 符号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "encoder_inputs = Input(shape=(seqX_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続（+Embeddingレイヤーのインスタンス化）\n",
    "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs) # shape: (seqX_len,)->(seqX_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（+LSTMレイヤーのインスタンス化）\n",
    "_, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)  # shape: (seqX_len, emb_dim)->(hid_dim, )\n",
    "# このLSTMレイヤーの出力に関しては下記に補足あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 復号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "decoder_inputs = Input(shape=(seqY_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続\n",
    "decoder_embedding = Embedding(ja_vocab_size, emb_dim) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)  # shape: (seqY_len,)->(seqY_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（encoder_statesを初期状態として指定）\n",
    "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states) # shape: (seqY_len, emb_dim)->(seqY_len, hid_dim)\n",
    "# LSTMレイヤーとDenseレイヤーを接続\n",
    "decoder_dense = Dense(ja_vocab_size, activation='softmax') # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # shape: (seqY_len, hid_dim)->(seqY_len, ja_vocab_size)\n",
    "\n",
    "# モデル構築（入力は符号化器＆復号化器、出力は復号化器のみ）\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "# 今回は、sparse_categorical_crossentropy（正解ラベルとしてone_hot表現のベクトルでなく数値を受け取るcategorical_crossentropy）を使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTMレイヤーの補足**\n",
    "\n",
    "LSTMの出力に関して補足の説明。下図はLSTMの模式図\n",
    "\n",
    "<img src=figures/lstm.png>\n",
    "\n",
    "**1.LSTMレイヤーはオプションがない場合はレイヤーの出力を返す**\n",
    "\n",
    "&emsp; output = LSTM()(x)\n",
    "\n",
    "このときの出力(output)とはLSTMの最後の隠れ状態$h$のことを指す。上図を3timestepと見るなら、$h_{t+2}$にあたる。\n",
    "\n",
    "**2.引数にreturn_state=Trueを指定されているときは隠れ状態も返す**\n",
    "\n",
    "&emsp; output, state_h, state_c = LSTM(return_state=True)(x)\n",
    "\n",
    "このときのstate_hとstate_cはそれぞれのLSTMの最後の隠れ状態$h$とセル状態$c$となる。上図を3timestepと見るなら、state_hは$h_{t+2}$、state_cは $c_{t+2}$ にあたる。output=state_hとなっていることに注意。\n",
    "\n",
    "また、以下のコード\n",
    "\n",
    "&emsp; _, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)\n",
    "\n",
    "を説明すると、まず、outputは今回参照しないので_(アンダーバー)を用いており、*(スター)を用いることでencoder_states=[state_h, state_c]となるような代入を行っている。(pythonの一般の使いかた)\n",
    "\n",
    "**3.引数にreturn_sequences=Trueを指定されているときは系列も返す**\n",
    "\n",
    "&emsp; outputs, state_h, state_c = LSTM(return_state=True, return_sequences=True)(x)\n",
    "\n",
    "このときoutputsは系列すべての出力を含む。上図を3timestepとみる場合はoutputsに$h_t$、$h_{t+1}$、$h_{t+2}$のすべての出力を含むということになる。\n",
    "\n",
    "### 2.2 モデルの学習\n",
    "モデルの学習時には、教師データとして1時点先の単語を示すデータを入力する。(train_target)\n",
    "\n",
    "学習時には、Decorderの入力に教師データを用いる。\n",
    "\n",
    "<img src=figures/training.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/15\n",
      "39200/39200 [==============================] - 3277s 84ms/step - loss: 1.8077 - val_loss: 1.7675\n",
      "Epoch 2/15\n",
      "39200/39200 [==============================] - 3545s 90ms/step - loss: 1.6501 - val_loss: 1.6573\n",
      "Epoch 3/15\n",
      "39200/39200 [==============================] - 4134s 105ms/step - loss: 1.5227 - val_loss: 1.5585\n",
      "Epoch 4/15\n",
      "39200/39200 [==============================] - 4388s 112ms/step - loss: 1.4139 - val_loss: 1.4835\n",
      "Epoch 5/15\n",
      "39200/39200 [==============================] - 3803s 97ms/step - loss: 1.3194 - val_loss: 1.4261\n",
      "Epoch 6/15\n",
      "39200/39200 [==============================] - 3240s 83ms/step - loss: 1.2363 - val_loss: 1.3724\n",
      "Epoch 7/15\n",
      "39200/39200 [==============================] - 3238s 83ms/step - loss: 1.1632 - val_loss: 1.3303\n",
      "Epoch 8/15\n",
      "39200/39200 [==============================] - 3256s 83ms/step - loss: 1.0979 - val_loss: 1.3078\n",
      "Epoch 9/15\n",
      "39200/39200 [==============================] - 3267s 83ms/step - loss: 1.0408 - val_loss: 1.2812\n",
      "Epoch 10/15\n",
      "39200/39200 [==============================] - 3252s 83ms/step - loss: 0.9894 - val_loss: 1.2633\n",
      "Epoch 11/15\n",
      "39200/39200 [==============================] - 3305s 84ms/step - loss: 0.9409 - val_loss: 1.2585\n",
      "Epoch 12/15\n",
      "39200/39200 [==============================] - 3264s 83ms/step - loss: 0.8971 - val_loss: 1.2481\n",
      "Epoch 13/15\n",
      "39200/39200 [==============================] - 3458s 88ms/step - loss: 0.8552 - val_loss: 1.2469\n",
      "Epoch 14/15\n",
      "39200/39200 [==============================] - 3249s 83ms/step - loss: 0.8171 - val_loss: 1.2441\n",
      "Epoch 15/15\n",
      "39200/39200 [==============================] - 3251s 83ms/step - loss: 0.7820 - val_loss: 1.2469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15108340390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
    "\n",
    "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=128, epochs=15, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
