{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2 実装①\n",
    "\n",
    "LSTMを使ったSeq2Seqモデルで英日機械翻訳を行ってみる。\n",
    "\n",
    "使用するデータセット、train.enとtrain.jaの中身は以下のようになっている。\n",
    "\n",
    "train.enの中身 (英語の文)\n",
    "\n",
    "i can 't tell who will arrive first .\n",
    "many animals have been destroyed by men .\n",
    "i 'm in the tennis club .\n",
    "︙\n",
    "\n",
    "train.jaの中身(日本語の文, 対訳)\n",
    "\n",
    "誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
    "多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
    "私 は テニス 部員 で す 。\n",
    "︙\n",
    "\n",
    "### 2.0 データの用意\n",
    "\n",
    "まず、データを読み込む。\n",
    "\n",
    "読み込む際に、文頭を表す仮想単語(**BOS**, Beggining Of Sentence)として＜s＞、文末を表す仮想単語(**EOS**, End Of Sentence)として＜¥s＞を付加する。\n",
    "\n",
    "また、BOS・EOSをつけた文章について、Tokenizerによって数値化を行う。\n",
    "\n",
    "最後に、バッチ処理のため、各系列の長さをそろえておく。keras.preprocessing.sequence.pad_sequenceを用いる。\n",
    "\n",
    "<img src=figures/preprocess.png>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanor\\Anaconda3\\envs\\matsuo\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(file_path):\n",
    "    tokenizer = Tokenizer(filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
    "\n",
    "# 読み込み＆Tokenizerによる数値化\n",
    "x_train, tokenizer_en = load_data('data/train.en')\n",
    "y_train, tokenizer_ja = load_data('data/train.ja')\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.02, random_state=42)\n",
    "\n",
    "# パディング\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "\n",
    "seqX_len = len(x_train[0])\n",
    "seqY_len = len(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 モデル構築\n",
    "ここではLSTMを使用してSeq2Seqモデルを構築してみる。\n",
    "\n",
    "Embeddingレイヤーでは、mask_zero=Trueを指定することで、計算時に前述したパディング部分を無視するようにしている。\n",
    "\n",
    "また、Reccurentレイヤーに対するreturn_state=Trueやreturn_sequence=Trueの指定をLSTMレイヤーの生成時に行っている。\n",
    "\n",
    "※Functional APIによるモデル構築であることに注意\n",
    "\n",
    "<img src=figures/model.png>\n",
    "\n",
    "上図での各レイヤーの対応\n",
    "- 符号化器Embeddingレイヤー : EncoderのEmbedding\n",
    "- 符号化器再帰レイヤー : Encoder(LSTM)\n",
    "- 復号化器Embeddingレイヤー : DecorderのEmbedding\n",
    "- 復号化器再帰レイヤー : Decorder(LSTM)\n",
    "- 復号化器出力レイヤー : Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, LSTM\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "\n",
    "## 符号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "encoder_inputs = Input(shape=(seqX_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続（+Embeddingレイヤーのインスタンス化）\n",
    "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs) # shape: (seqX_len,)->(seqX_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（+LSTMレイヤーのインスタンス化）\n",
    "_, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)  # shape: (seqX_len, emb_dim)->(hid_dim, )\n",
    "# このLSTMレイヤーの出力に関しては下記に補足あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 復号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "decoder_inputs = Input(shape=(seqY_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続\n",
    "decoder_embedding = Embedding(ja_vocab_size, emb_dim) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)  # shape: (seqY_len,)->(seqY_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（encoder_statesを初期状態として指定）\n",
    "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states) # shape: (seqY_len, emb_dim)->(seqY_len, hid_dim)\n",
    "# LSTMレイヤーとDenseレイヤーを接続\n",
    "decoder_dense = Dense(ja_vocab_size, activation='softmax') # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # shape: (seqY_len, hid_dim)->(seqY_len, ja_vocab_size)\n",
    "\n",
    "# モデル構築（入力は符号化器＆復号化器、出力は復号化器のみ）\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "# 今回は、sparse_categorical_crossentropy（正解ラベルとしてone_hot表現のベクトルでなく数値を受け取るcategorical_crossentropy）を使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTMレイヤーの補足**\n",
    "\n",
    "LSTMの出力に関して補足の説明。下図はLSTMの模式図\n",
    "\n",
    "<img src=figures/lstm.png>\n",
    "\n",
    "**1.LSTMレイヤーはオプションがない場合はレイヤーの出力を返す**\n",
    "\n",
    "&emsp; output = LSTM()(x)\n",
    "\n",
    "このときの出力(output)とはLSTMの最後の隠れ状態$h$のことを指す。上図を3timestepと見るなら、$h_{t+2}$にあたる。\n",
    "\n",
    "**2.引数にreturn_state=Trueを指定されているときは隠れ状態も返す**\n",
    "\n",
    "&emsp; output, state_h, state_c = LSTM(return_state=True)(x)\n",
    "\n",
    "このときのstate_hとstate_cはそれぞれのLSTMの最後の隠れ状態$h$とセル状態$c$となる。上図を3timestepと見るなら、state_hは$h_{t+2}$、state_cは $c_{t+2}$ にあたる。output=state_hとなっていることに注意。\n",
    "\n",
    "また、以下のコード\n",
    "\n",
    "&emsp; _, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)\n",
    "\n",
    "を説明すると、まず、outputは今回参照しないので_(アンダーバー)を用いており、*(スター)を用いることでencoder_states=[state_h, state_c]となるような代入を行っている。(pythonの一般の使いかた)\n",
    "\n",
    "**3.引数にreturn_sequences=Trueを指定されているときは系列も返す**\n",
    "\n",
    "&emsp; outputs, state_h, state_c = LSTM(return_state=True, return_sequences=True)(x)\n",
    "\n",
    "このときoutputsは系列すべての出力を含む。上図を3timestepとみる場合はoutputsに$h_t$、$h_{t+1}$、$h_{t+2}$のすべての出力を含むということになる。\n",
    "\n",
    "### 2.2 モデルの学習\n",
    "モデルの学習時には、教師データとして1時点先の単語を示すデータを入力する。(train_target)\n",
    "\n",
    "学習時には、Decorderの入力に教師データを用いる。\n",
    "\n",
    "<img src=figures/training.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/15\n",
      "39200/39200 [==============================] - 3277s 84ms/step - loss: 1.8077 - val_loss: 1.7675\n",
      "Epoch 2/15\n",
      "39200/39200 [==============================] - 3545s 90ms/step - loss: 1.6501 - val_loss: 1.6573\n",
      "Epoch 3/15\n",
      "39200/39200 [==============================] - 4134s 105ms/step - loss: 1.5227 - val_loss: 1.5585\n",
      "Epoch 4/15\n",
      "39200/39200 [==============================] - 4388s 112ms/step - loss: 1.4139 - val_loss: 1.4835\n",
      "Epoch 5/15\n",
      "39200/39200 [==============================] - 3803s 97ms/step - loss: 1.3194 - val_loss: 1.4261\n",
      "Epoch 6/15\n",
      "39200/39200 [==============================] - 3240s 83ms/step - loss: 1.2363 - val_loss: 1.3724\n",
      "Epoch 7/15\n",
      "39200/39200 [==============================] - 3238s 83ms/step - loss: 1.1632 - val_loss: 1.3303\n",
      "Epoch 8/15\n",
      "39200/39200 [==============================] - 3256s 83ms/step - loss: 1.0979 - val_loss: 1.3078\n",
      "Epoch 9/15\n",
      "39200/39200 [==============================] - 3267s 83ms/step - loss: 1.0408 - val_loss: 1.2812\n",
      "Epoch 10/15\n",
      "39200/39200 [==============================] - 3252s 83ms/step - loss: 0.9894 - val_loss: 1.2633\n",
      "Epoch 11/15\n",
      "39200/39200 [==============================] - 3305s 84ms/step - loss: 0.9409 - val_loss: 1.2585\n",
      "Epoch 12/15\n",
      "39200/39200 [==============================] - 3264s 83ms/step - loss: 0.8971 - val_loss: 1.2481\n",
      "Epoch 13/15\n",
      "39200/39200 [==============================] - 3458s 88ms/step - loss: 0.8552 - val_loss: 1.2469\n",
      "Epoch 14/15\n",
      "39200/39200 [==============================] - 3249s 83ms/step - loss: 0.8171 - val_loss: 1.2441\n",
      "Epoch 15/15\n",
      "39200/39200 [==============================] - 3251s 83ms/step - loss: 0.7820 - val_loss: 1.2469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15108340390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
    "\n",
    "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=128, epochs=15, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 モデルによる生成\n",
    "\n",
    "先程学習したモデルを使用して、系列を生成してみる。\n",
    "\n",
    "そのためにまずは学習したモデルを組み込んだ、系列生成用のモデルを構築ずる。\n",
    "\n",
    "学習時との違いは、復号化器が1ステップずつ実行できるよう、状態ベクトルの入力と出力をモデルの定義に加えている点。\n",
    "\n",
    "(また、1ステップ前の状態を引き継いで生成が可能になるように、復号化器のモデルの初期状態を指定可能にしている。)\n",
    "\n",
    "生成する際のDecoderの入力には翻訳先の教師データは用いない。\n",
    "\n",
    "<img src=figures/prediction.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b324ec052fc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 符号化器（学習時と同じ構成、学習したレイヤーを利用）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mencoder_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 復号化器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "# サンプリング用（生成用）のモデルを作成\n",
    "\n",
    "# 符号化器（学習時と同じ構成、学習したレイヤーを利用）\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 復号化器\n",
    "decoder_states_inputs = [Input(shape=(hid_dim,)), Input(shape=(hid_dim,))] # decorder_lstmの初期状態指定用(h_t, c_t)\n",
    "\n",
    "decoder_inputs = Input(shape=(1,))\n",
    "decoder_embedded = decoder_embedding(decoder_inputs) # 学習済みEmbeddingレイヤーを利用\n",
    "decoder_outputs, *decoder_states = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs) # 学習済みLSTMレイヤーを利用\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # 学習済みDenseレイヤーを利用\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このモデルを使用した生成（予測）を行ってみましょう。\n",
    "\n",
    "生成では、未知のデータに対してモデルを適用するので正解ラベルはわかりません。\n",
    "\n",
    "そこで、代わりに前のステップで予測した単語を各ステップでの入力とします。\n",
    "\n",
    "そして, 系列の終わりを表す単語 (＜/s＞) が出力されるまで繰り返します。（最初の入力は＜s＞を使用します）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, bos_eos, max_output_length = 1000):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.array(bos_eos[0])  # bos_eos[0]=\"<s>\"に対応するインデックス\n",
    "    output_seq= bos_eos[0][:]\n",
    "    \n",
    "    while True:\n",
    "        output_tokens, *states_value = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = [np.argmax(output_tokens[0, -1, :])]\n",
    "        output_seq += sampled_token_index\n",
    "        \n",
    "        if (sampled_token_index == bos_eos[1] or len(output_seq) > max_output_length):\n",
    "            break\n",
    "\n",
    "        target_seq = np.array(sampled_token_index)\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer_en' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cca1fcc5479a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdetokenizer_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_en\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdetokenizer_ja\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer_ja\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_no\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqX_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer_en' is not defined"
     ]
    }
   ],
   "source": [
    "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
    "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))\n",
    "\n",
    "text_no = 0\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
    "print('生成文:', ' '.join([detokenizer_ja[i] for i in decode_sequence(input_seq, bos_eos)]))\n",
    "print('正解文:', ' '.join([detokenizer_ja[i] for i in y_test[text_no]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 モデルの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanor\\Anaconda3\\envs\\matsuo\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2cabf02ce23a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 機械翻訳の評価について（補足）\n",
    "これまで、基本的に学習したモデルの良し悪しについては損失をベースに考えてきました。\n",
    "\n",
    "ですが機械翻訳の場合、損失と翻訳の精度が必ずしも一致しません。\n",
    "\n",
    "というのも、翻訳においては、単純に各単語が一致しているか否か以上に、意味的な繋がりや表現の流暢さが重要となるためです。\n",
    "\n",
    "また、必ずしも語順についても一致している必要はありません。\n",
    "\n",
    "そこで、そうした翻訳タスク特有の性質を反映した評価指標が必要となります。その代表例として、BLEUスコアが挙げられます。\n",
    "\n",
    "BLEUスコアは、n-gram（連続n単語. 主にn=4）がどれだけ生成文と正解文で共有されているかなどを考慮した指標となっています。\n",
    "\n",
    "機械翻訳は本講座の主目的ではないので、ここではその詳細な算出方法等は触れませんが、興味がある方はスクリプト（http://www.nltk.org/_modules/nltk/translate/bleu_score.html ）をのぞいてみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5506953149031837\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "prediction = ['I', 'am', 'a', 'graduate', 'student', 'at', 'a', 'university']\n",
    "reference = [['I', 'am', 'a', 'graduate', 'student', 'at', 'the', 'university', 'of', 'tokyo']]\n",
    "\n",
    "print(sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pad_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4ff0473d523a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_no\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseqX_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_ja\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"<s>\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"</s>\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdetokenizer_ja\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbos_eos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pad_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "text_no = 1\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "prediction = [detokenizer_ja[i] for i in decode_sequence(input_seq, bos_eos)]\n",
    "reference = [[detokenizer_ja[i] for i in y_test[text_no]]]\n",
    "\n",
    "print(prediction)\n",
    "print(reference)\n",
    "\n",
    "print(sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このBLEUスコアの他にも、機械翻訳の評価指標がいくつか提案されています。\n",
    "\n",
    "代表的なものの比較は、\n",
    "\n",
    "N. Graham, \"文レベルの機械翻訳評価尺度に関する調査\", 研究報告自然言語処理, vol. 2013-NL-212, no. 7, pp. 1–8, 2013. (http://phontron.com/paper/neubig13nl212.pdf)\n",
    "\n",
    "などにまとめられているので、機械翻訳に興味のあるかたは参照してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
